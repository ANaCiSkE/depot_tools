{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "824cacd6_13d8346b",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1577257
      },
      "writtenOn": "2024-07-23T19:43:04Z",
      "side": 1,
      "message": "Cool! That sounds like a nice optimization and good tradeoff (the machines that we have rarely seem to be able to use all that RAM :)).\n\nDo you have some benchmark numbers that show the difference in CPU time and memory consumption? Due to lack of experience with Go GC tuning I have absolutely no intuition about how much we\u0027re talking about here.",
      "revId": "1d9259eac5c7ad39713f9a5be8645aeb2546e8de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "4fe10a2e_de54cbca",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1444553
      },
      "writtenOn": "2024-07-23T19:53:15Z",
      "side": 1,
      "message": "https://tip.golang.org/doc/gc-guide\n\nWhat this knob does is determine when a gc is triggered based on \u0027new heap\u0027 size vs \u0027live heap\u0027 from the previous gc cycle.  New heap is stuff freshly allocated since the previous cycle, and live heap is what was still around at the end of the last cycle.  It\u0027s a percentage of new heap to live heap.\n\nThe default is 100, so that will trigger a gc whenever the amount of newly allocated heap is 100% of what was live before.  This sets it to 500, so it gcs less frequently.  The CPU cost is fairly constant (explained in the link), so gcing less is actually less cpu intensive overall.",
      "parentUuid": "824cacd6_13d8346b",
      "revId": "1d9259eac5c7ad39713f9a5be8645aeb2546e8de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "54f2bab9_d2181bb0",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1444553
      },
      "writtenOn": "2024-07-23T20:14:28Z",
      "side": 1,
      "message": "In terms of actual numbers I found on linux that going from 100 to 500 reduces GC CPU % from around 3-5% to under 1%.  So not a huge impact there, but an impact nontheless.\n\nI have a feeling (possibly an incorrect one) that frequent GC cycling could be the cause of the occasional complaints about builds slowing down after they have been running for a while.",
      "parentUuid": "4fe10a2e_de54cbca",
      "revId": "1d9259eac5c7ad39713f9a5be8645aeb2546e8de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "c24313fc_8e9f872d",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1577257
      },
      "writtenOn": "2024-07-23T22:13:23Z",
      "side": 1,
      "message": "@ukai@google.com Do you have some advice or any concerns for this change?",
      "revId": "1d9259eac5c7ad39713f9a5be8645aeb2546e8de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "49e71a3b_665e364b",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1001939
      },
      "writtenOn": "2024-07-23T22:46:58Z",
      "side": 1,
      "message": "won\u0027t this change cause more bot die with OOM?",
      "parentUuid": "c24313fc_8e9f872d",
      "revId": "1d9259eac5c7ad39713f9a5be8645aeb2546e8de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "1359135f_3d7d460c",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1001939
      },
      "writtenOn": "2024-07-23T23:59:05Z",
      "side": 1,
      "message": "ah, nvm. it is not used on bot.\nbtw, this GC problem only happens for developers, not on bot?\nthere are leak in reproxy?\n\nbetter to set GOGC just for start_reproxy ?",
      "parentUuid": "49e71a3b_665e364b",
      "revId": "1d9259eac5c7ad39713f9a5be8645aeb2546e8de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "44000b09_91acaf8c",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1577257
      },
      "writtenOn": "2024-07-25T07:52:45Z",
      "side": 1,
      "message": "I thought about this some more, and I think we should first rule out that a memory leak is responsible for this GC issue. I fear that if we add this, we\u0027ll never remove it again, because it will be very hard to prove that it is safe to do so, and we\u0027ll incur the higher memory consumption from then on. :/\n\nIf that increased consumption causes a developer machine to start swapping out memory to disk or not be able to cache as many files in RAM anymore, they\u0027ll be in an even worse situation for performance. A lot of developers build Chromium on notebooks, because thanks to remote execution that\u0027s actually feasible now, and we don\u0027t want to break that use case.\n\nOf course if we can\u0027t find any other way, and reproxy turns out to be a legitimate case where the GC needs some tuning to perform well, we can think about it. Just want to be careful.\n\nWDYT?",
      "revId": "1d9259eac5c7ad39713f9a5be8645aeb2546e8de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0a6182e8_44b3e860",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1544499
      },
      "writtenOn": "2024-07-29T15:56:34Z",
      "side": 1,
      "message": "This is not to address a current memory leak. We had a memory leak up until 148 [1] which caused memory to continously be allocated and the garbage collection to not run at all. At 150 the memory leak is fixed [2] but this now exposes the tradeoff between cpu and memory that is controlled by GOGC, internally for example there is precedent for setting this higher [3]. By setting this higher we see a drop in cpu usage due to less GC cycles with an memory increase but still less memory than with the previous memory leaking code.\n\n[1] http://shortn/_Y2K7p1pN4j\n[2] http://shortn/_ZghlqNZeQ1\n[3] go/flume-diagnosis#flumego-ooms\n[4] http://shortn/_FprNRsTwPp",
      "parentUuid": "44000b09_91acaf8c",
      "revId": "1d9259eac5c7ad39713f9a5be8645aeb2546e8de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "f6dfb88b_a60d43bf",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1577257
      },
      "writtenOn": "2024-08-01T01:55:44Z",
      "side": 1,
      "message": "OK, thank you for the explanation!\n\nI found this guidance in a discussion on our Go mailing list that sounds encouraging: \"On a final note, GOGC and GOMEMLIMIT are much more about the throughput/memory tradeoff, because that is much more zero-sum. Using more memory for the heap very directly means entering the GC\u0027s concurrent mark phase less often, which means both better throughput and often a lower latency impact.\"\n\nHowever, people also noted on that thread that \"there have been few or no patterns that emerged where we could generalize some findings\", with the one you\u0027ve linked to (Flume) being cited as the notable exception where setting GOGC\u003d500 seems to always result in an improvement.\n\nAs I really have no good intuition about the potential benefits in CPU and/or wall time saved vs. increase of memory consumption, let\u0027s get some hyperfine results for default GOGC and GOGC\u003d500 that show the impact on times, and also measure the maximum memory usage of reproxy.\n\nMaybe something like this works:\n\n```\n$ hyperfine --show-output --runs\u003d1 \\\n    --prepare \"gn clean out/default; gn gen out/default --args\u003d\u0027is_debug\u003dtrue use_remoteexec\u003dtrue\u0027\" \\\n    \"autoninja -C out/default all\" \\\n    \"GOGC\u003d500 autoninja -C out/default all\"\n```\n\nThen let\u0027s quickly grab the PID of reproxy and monitor it in Process Explorer on Windows, or `grep -E \u0027(VmPeak|VmHWM)\u0027 /proc/${REPROXY_PID}/status` on Linux.",
      "parentUuid": "0a6182e8_44b3e860",
      "revId": "1d9259eac5c7ad39713f9a5be8645aeb2546e8de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "add9b25a_e725fe6c",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1577257
      },
      "writtenOn": "2024-08-01T10:55:53Z",
      "side": 1,
      "message": "Unfortunately I didn\u0027t have time to run benchmarks today and I\u0027m taking a vacation day tomorrow. Could someone run the benchmark as described above? It would be great to understand the impact and risk of the change better and if it looks good, I think I don\u0027t have any remaining worries about this :)",
      "parentUuid": "f6dfb88b_a60d43bf",
      "revId": "1d9259eac5c7ad39713f9a5be8645aeb2546e8de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8aa2cc13_ab7da369",
        "filename": "reclient_helper.py",
        "patchSetId": 1
      },
      "lineNbr": 350,
      "author": {
        "id": 1577257
      },
      "writtenOn": "2024-08-01T01:55:44Z",
      "side": 1,
      "message": "I think this will also affect Siso and any other Go binary that runs as part of the build. We should probably set this environment variable only when starting reproxy itself, and not globally for the environment.",
      "range": {
        "startLine": 348,
        "startChar": 0,
        "endLine": 350,
        "endChar": 40
      },
      "revId": "1d9259eac5c7ad39713f9a5be8645aeb2546e8de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    }
  ]
}